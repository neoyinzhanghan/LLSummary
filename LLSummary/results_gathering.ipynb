{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GATHER RESULTS FOLDERS\n",
    "You add in CSVs of your cohort files in this block and the directory you want to save the results, and it will pool the slide results folders of your intended save directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from LLSummary.utils import rsync_with_retries\n",
    "\n",
    "cohort_files = []\n",
    "save_dir = \"/media/hdd3/greg/test\"\n",
    "\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "metadata_dict = {\n",
    "    \"cohort_file\": [],\n",
    "    \"wsi_name\": [],\n",
    "    \"username\": [],\n",
    "    \"hostname\": [],\n",
    "    \"machine\": [],\n",
    "    \"remote_result_dir\": [],\n",
    "    \"Dx\": [],\n",
    "    \"sub_Dx\": [],\n",
    "    \"datetime_processed\": [],\n",
    "    \"note\": [],\n",
    "}\n",
    "\n",
    "for cohort_file in cohort_files:\n",
    "    print(f\"Processing {cohort_file}.\")\n",
    "\n",
    "    df = pd.read_csv(cohort_file)\n",
    "\n",
    "    # Iterate over rows using tqdm\n",
    "    for i, row in tqdm(df.iterrows(), total=df.shape[0]):\n",
    "        username = row[\"username\"]\n",
    "        hostname = row[\"hostname\"]\n",
    "        remote_result_dir = row[\"remote_result_dir\"]\n",
    "\n",
    "        # Define the local directory to save the data\n",
    "        local_dir = os.path.join(save_dir, os.path.basename(remote_result_dir))\n",
    "\n",
    "        # remove the local directory if it already exists, which means we always overwrite the data\n",
    "        # NOTE ths behaviour is expected because the data pooling right now is for viewing purposes only\n",
    "        if os.path.exists(local_dir):\n",
    "            os.rmdir(local_dir)\n",
    "\n",
    "        # Run the rsync command with retries and exponential backoff\n",
    "        rsync_with_retries(\n",
    "            username,\n",
    "            hostname,\n",
    "            remote_result_dir,\n",
    "            local_dir,\n",
    "        )\n",
    "\n",
    "        # Add metadata to the metadata_dict\n",
    "        metadata_dict[\"cohort_file\"].append(cohort_file)\n",
    "        metadata_dict[\"wsi_name\"].append(row[\"wsi_name\"])\n",
    "        metadata_dict[\"username\"].append(username)\n",
    "        metadata_dict[\"hostname\"].append(hostname)\n",
    "        metadata_dict[\"machine\"].append(row[\"machine\"])\n",
    "        metadata_dict[\"remote_result_dir\"].append(remote_result_dir)\n",
    "        metadata_dict[\"Dx\"].append(row[\"Dx\"])\n",
    "        metadata_dict[\"sub_Dx\"].append(row[\"sub_Dx\"])\n",
    "        metadata_dict[\"datetime_processed\"].append(row[\"datetime_processed\"])\n",
    "        metadata_dict[\"note\"].append(row[\"note\"])\n",
    "\n",
    "# Save the metadata_dict as a DataFrame\n",
    "metadata_df = pd.DataFrame(metadata_dict)\n",
    "\n",
    "# Save the metadata_df as a CSV file\n",
    "metadata_df.to_csv(os.path.join(save_dir, \"metadata.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bootstrap Cell Cartridges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from LLSummary.utils import rsync_with_retries\n",
    "\n",
    "cohort_files = []\n",
    "save_dir = \"/media/hdd3/greg/test\"\n",
    "\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "metadata_dict = {\n",
    "    \"cohort_file\": [],\n",
    "    \"wsi_name\": [],\n",
    "    \"username\": [],\n",
    "    \"hostname\": [],\n",
    "    \"machine\": [],\n",
    "    \"remote_result_dir\": [],\n",
    "    \"Dx\": [],\n",
    "    \"sub_Dx\": [],\n",
    "    \"datetime_processed\": [],\n",
    "    \"note\": [],\n",
    "}\n",
    "\n",
    "for cohort_file in cohort_files:\n",
    "    print(f\"Processing {cohort_file}.\")\n",
    "\n",
    "    df = pd.read_csv(cohort_file)\n",
    "\n",
    "    # Iterate over rows using tqdm\n",
    "    for i, row in tqdm(df.iterrows(), total=df.shape[0]):\n",
    "        username = row[\"username\"]\n",
    "        hostname = row[\"hostname\"]\n",
    "        remote_result_dir = row[\"remote_result_dir\"]\n",
    "\n",
    "        # Define the local directory to save the data\n",
    "        local_dir = os.path.join(save_dir, os.path.basename(remote_result_dir))\n",
    "\n",
    "        # remove the local directory if it already exists, which means we always overwrite the data\n",
    "        # NOTE ths behaviour is expected because the data pooling right now is for viewing purposes only\n",
    "        if os.path.exists(local_dir):\n",
    "            os.rmdir(local_dir)\n",
    "\n",
    "        # Run the rsync command with retries and exponential backoff\n",
    "        rsync_with_retries(\n",
    "            username,\n",
    "            hostname,\n",
    "            remote_result_dir,\n",
    "            local_dir,\n",
    "        )\n",
    "\n",
    "        # Add metadata to the metadata_dict\n",
    "        metadata_dict[\"cohort_file\"].append(cohort_file)\n",
    "        metadata_dict[\"wsi_name\"].append(row[\"wsi_name\"])\n",
    "        metadata_dict[\"username\"].append(username)\n",
    "        metadata_dict[\"hostname\"].append(hostname)\n",
    "        metadata_dict[\"machine\"].append(row[\"machine\"])\n",
    "        metadata_dict[\"remote_result_dir\"].append(remote_result_dir)\n",
    "        metadata_dict[\"Dx\"].append(row[\"Dx\"])\n",
    "        metadata_dict[\"sub_Dx\"].append(row[\"sub_Dx\"])\n",
    "        metadata_dict[\"datetime_processed\"].append(row[\"datetime_processed\"])\n",
    "        metadata_dict[\"note\"].append(row[\"note\"])\n",
    "\n",
    "# Save the metadata_dict as a DataFrame\n",
    "metadata_df = pd.DataFrame(metadata_dict)\n",
    "\n",
    "# Save the metadata_df as a CSV file\n",
    "metadata_df.to_csv(os.path.join(save_dir, \"metadata.csv\"), index=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
